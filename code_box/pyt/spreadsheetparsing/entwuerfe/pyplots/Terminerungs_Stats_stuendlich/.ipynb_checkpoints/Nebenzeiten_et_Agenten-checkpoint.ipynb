{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Import necessary modules\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import date2num, AutoDateFormatter, AutoDateLocator, WeekdayLocator, MonthLocator, DayLocator, DateLocator, DateFormatter\n",
    "from matplotlib.dates import MO, TU, WE, TH, FR, SA, SU\n",
    "from matplotlib.ticker import AutoMinorLocator, AutoLocator, FormatStrFormatter, ScalarFormatter\n",
    "import numpy as np\n",
    "import datetime, calendar\n",
    "from datetime import timedelta\n",
    "import matplotlib.patches as mpatches\n",
    "from itertools import tee\n",
    "from traitlets import traitlets\n",
    "\n",
    "sys.path.append(os.path.abspath('/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/entwuerfe/xls_testruns/lib/'))\n",
    "from ce_funclib import determine_kernzeit as dtkz\n",
    "from ce_funclib import continuity_check\n",
    "\n",
    "\n",
    "from ipywidgets import widgets, interact, interactive, fixed, interact_manual, Layout\n",
    "from IPython.display import display\n",
    "#%matplotlib inline\n",
    "%matplotlib tk\n",
    "\n",
    "\n",
    "## Import data frome pickle generated from muß ein file mit agentenstats sein\n",
    "arcpth='/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/test_stats/archiv/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## GET A LIST OF MATCHING .xls FILES FROM THE GIVEN DIRECTORY\n",
    "\n",
    "def collectxlfiles(arcpath):\n",
    "    xlfilelist=list()\n",
    "\n",
    "    for xlfile in os.listdir(arcpath):\n",
    "        if xlfile.startswith('CE_alle_Ag'):\n",
    "            xlfileabs=os.path.join(arcpath,xlfile)\n",
    "            xlfilelist.append(xlfileabs)\n",
    "    return sorted(xlfilelist)\n",
    "\n",
    "xlfilelist=collectxlfiles(arcpth)\n",
    "#xlfilelist\n",
    "#examplefile=xlfilelist[233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### TEST FOR DATA IN FILE, SORT OUT EMPTY FILES\n",
    "\n",
    "## good dataframes do per definition not contain any zero values\n",
    "## fill bad DFs with nan?\n",
    "\n",
    "def filetoframe(exfile):\n",
    "    exframe=pd.read_excel(exfile) # this is a regular pd.DataFrame\n",
    "    datecell=exframe.iloc[0,1]\n",
    "    sheet_datetime=pd.to_datetime(datecell,format='%d.%m %Y : %H')\n",
    "    sheet_date=sheet_datetime.date()\n",
    "    \n",
    "    integritycheck=exframe.iloc[2,1] # files with data have \"agenten\" here, files with no calls have a 'nan'\n",
    "\n",
    "    if integritycheck != 'Agenten':\n",
    "        # if it's empty, keep date for filling it later\n",
    "        print('Exception: ', end='')\n",
    "        except_status='ex'\n",
    "        \n",
    "        usefulcols={0:'tstamp',1:'agent',3:'an',4:'be',22:'vl',24:'ht_float',29:'tt_float'} # map cols to decent names\n",
    "        exframe=exframe.reindex(columns=sorted(usefulcols.keys()))\n",
    "        exframe.rename(columns=usefulcols,inplace=True)        \n",
    "        exframe=exframe[0:1] # strip text rows and the mangled sum row\n",
    "        print(sheet_datetime)\n",
    "        \n",
    "        exframe['tstamp']=sheet_datetime\n",
    "        exframe['date']=sheet_date\n",
    "        exframe['agent']='nocalls_datum'\n",
    "        exframe[['wd','ww','mm','yy']]=exframe['tstamp'].dt.strftime('%a,%W,%m,%Y').str.split(',',expand=True) # make ww,yy,mm,wd columns\n",
    "        exframe['bz']=exframe['tstamp'].apply(dtkz)\n",
    "        exframe['ort']=exframe['agent'].str[0] # split the identifier into useable columns\n",
    "        exframe['id']='foobar' # split the identifier into useable columns\n",
    "        \n",
    "        # integers should be of appropriate datatype, we received them as strings\n",
    "        # exframe[['vl','an','be','ww','mm','yy']]=exframe[['vl','an','be','ww','mm','yy']].astype(np.int64) #just for the beauty of it\n",
    "        exframe.fillna(0, inplace=True) \n",
    "        exframe[['ww','mm','yy']]=exframe[['ww','mm','yy']].astype(np.int64) #just for the beauty of it\n",
    "        #exframe.fillna(0, inplace=True) \n",
    "        return exframe,except_status\n",
    "        \n",
    "    else:\n",
    "        except_status='reg'\n",
    "        \n",
    "        exframe.columns=range(0,30) # rename columns to a temporarily more readable format, fancy rename later\n",
    "        usefulcols={0:'tstamp',1:'agent',3:'an',4:'be',22:'vl',24:'ht_float',29:'tt_float'} # map cols to decent names\n",
    "        exframe=exframe[sorted(usefulcols.keys())] # skip cols and keep the ones we need\n",
    "        exframe.rename(columns=usefulcols,inplace=True) # rename cols\n",
    "        exframe=exframe[3:-1] # strip text rows and the mangled sum row\n",
    "        exframe['tstamp']=pd.to_datetime(exframe['tstamp'],format=' %d.%m.%Y %H:%M ')\n",
    "        exframe['date']=exframe['tstamp'].dt.date\n",
    "        exframe[['wd','ww','mm','yy']]=exframe['tstamp'].dt.strftime('%a,%W,%m,%Y').str.split(',',expand=True) # make ww,yy,mm,wd columns\n",
    "        exframe['bz']=exframe['tstamp'].apply(dtkz)\n",
    "        \n",
    "        exframe['ort']=exframe['agent'].str[0] # split the identifier into useable columns\n",
    "        exframe['id']=exframe['agent'].str[-6:] # split the identifier into useable columns\n",
    "        exframe['agent']=exframe['agent'].str[2:-7] # split the identifier into useable columns\n",
    "        \n",
    "        # integers should be of appropriate datatype, we received them as strings\n",
    "        exframe[['vl','an','be','ww','mm','yy']]=exframe[['vl','an','be','ww','mm','yy']].astype(np.int64) #just for the beauty of it\n",
    "\n",
    "        return exframe,except_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: 2017-04-17 00:00:00\n",
      "Exception: 2017-05-14 00:00:00\n",
      "Exception: 2017-11-19 00:00:00\n",
      "Exception: 2017-12-03 00:00:00\n",
      "Exception: 2017-12-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "framelist=list()\n",
    "exceptionlist=list()\n",
    "for xfile in xlfilelist:\n",
    "    frame_from_file,except_status=filetoframe(xfile)\n",
    "    if except_status=='ex':\n",
    "        exceptionlist.append(xfile)\n",
    "    framelist.append(frame_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### produce a unified frame with all data and sort it by timstamp and agentname\n",
    "bigframeii=pd.concat(framelist)\n",
    "bigframeii.sort_values(['tstamp','agent'],inplace=True)\n",
    "bigframeii.reset_index(drop=True,inplace=True) # there you go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# die exklusivlogins müssen zusammengelegt werden\n",
    "unify_id={'gesinst':'995887','stanzju':'878457','papkeda':'891914'}\n",
    "bigframeii.loc[bigframeii['id'] == unify_id['gesinst'],'agent'] = 'gesinst'\n",
    "bigframeii.loc[bigframeii['id'] == unify_id['stanzju'],'agent'] = 'stanzju'\n",
    "bigframeii.loc[bigframeii['id'] == unify_id['papkeda'],'agent'] = 'papkeda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check, ob alle Daten(Tage) lückenlos sind\n",
    "datenserie_uniq=bigframeii['date'].unique().tolist()\n",
    "tage_bestand=len(datenserie_uniq)\n",
    "tage_start=datenserie_uniq[0]\n",
    "tage_ende=datenserie_uniq[-1:]\n",
    "\n",
    "missing_dates=continuity_check(datenserie_uniq)\n",
    "if not missing_dates:\n",
    "    print('no dates are missing')\n",
    "else:\n",
    "    print('the following dates are not within the frame:')\n",
    "    print(missing_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all agents available and create frames for kern and neben\n",
    "allagents_list=sorted(bigframeii['agent'].unique())\n",
    "allagents_list.extend(['Hagenow','Berlin','Alle'])\n",
    "standorte=bigframeii.ort.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we can't figure out individual calls anyway, since raw data calls have been grouped by hours already  \n",
    "so we can go on and group by days to figure out averages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframeii.head(2)\n",
    "#Samstage = bigframeii.loc[(bigframeii['tstamp'].dt.dayofweek ==  5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Datum_MIN = bigframeii.tstamp.dt.date.min()\n",
    "Datum_MAX = bigframeii.tstamp.dt.date.max()\n",
    "\n",
    "Datum_VON = datetime.date(2017,5,1)   # YY,MM,DD\n",
    "Datum_BIS = datetime.date(2018,10,1)\n",
    "\n",
    "Kernzeit = (bigframeii['bz'] ==  'k')\n",
    "Nebnzeit = (bigframeii['bz'] ==  'n')\n",
    "\n",
    "Berlin = (bigframeii['ort'] ==  'B')\n",
    "Hagenow = (bigframeii['ort'] ==  'H')\n",
    "\n",
    "Wunschzeitraum = ((bigframeii.tstamp.dt.date >= Datum_VON) & (bigframeii.tstamp.dt.date <= Datum_BIS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bigframeii.loc[Wunschzeitraum & Kernzeit & Hagenow]   # SUPER!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kzdata=bigframeii.loc[Wunschzeitraum & Kernzeit].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kzdata_reindex=kzdata.set_index(['tstamp','ort']).copy() # timestamps und Standort als neue Indizes\n",
    "kzdata_byday=kzdata_reindex.groupby([pd.TimeGrouper('D', level='tstamp'), pd.Grouper(level='ort')]).sum() # nach Tagen gruppiert und alle Zahlen summiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotzi(frame):\n",
    "        \n",
    "    aht,aacw,att,nzb,bg =\"#003873\",\"#EE0042\",\"#899EB2\",\"#C7798F\",\"#FEFFE2\"\n",
    "    sonntage=WeekdayLocator(byweekday=(6), interval=2)\n",
    "    datevon=frame.index.get_level_values('tstamp').min().strftime('%d.%m.%y')\n",
    "    datebis=frame.index.get_level_values('tstamp').max().strftime('%d.%m.%y')\n",
    "    \n",
    "    \n",
    "    #### ------------------------------------ ####\n",
    "    \n",
    "    fig=plt.figure(figsize=(12,5))\n",
    "\n",
    "    ax=fig.add_subplot(111)\n",
    "    ax.margins(0,0)\n",
    "    ax.set_facecolor(bg)\n",
    "    ax.set_xlabel('Kernzeit / ceDis von '+datevon+' bis '+datebis)\n",
    "    ax.xaxis.set_major_locator(sonntage)\n",
    "    ax.xaxis.set_major_formatter(DateFormatter('%d.%m.%y'))\n",
    "    ax.set_ylabel('Calls angenommen')\n",
    "   \n",
    "    \n",
    "    ber=frame.xs('B', level=1, drop_level=True)['an']\n",
    "    hgw=frame.xs('H', level=1, drop_level=True)['an']\n",
    "\n",
    "    b=ax.bar(ber.index,ber.values, label='calls', color=nzb, width=1)\n",
    "    h=ax.bar(hgw.index,hgw.values, label='calls', color=aht, width=0.6)\n",
    "    \n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, horizontalalignment='right', size=6 )\n",
    "    \n",
    "    bercalls=int(ber.sum())\n",
    "    hgwcalls=int(hgw.sum())\n",
    "    allecalls=bercalls+hgwcalls\n",
    "    anteilhgw=str(    format((hgwcalls/allecalls)*100,'.2f')   )  \n",
    "    anteilber=str(    format((bercalls/allecalls)*100,'.2f')   )\n",
    "\n",
    "    \n",
    "    \n",
    "    callsBH = mpatches.Patch(color='000000', label='Calls Ber+Hgw: '+str(allecalls))\n",
    "    callsB = mpatches.Patch(color=nzb, label='Calls Ber: '+str(bercalls) +' ('+anteilber+'%)'        )\n",
    "    callsH = mpatches.Patch(color=aht, label='Calls Hgw: '+str(hgwcalls) +' ('+anteilhgw+'%)'        )\n",
    "\n",
    "    ax.legend(handles=[callsBH,callsB,callsH],fontsize=8,ncol=2,loc='upper right',borderaxespad=-2,framealpha=0.99)\n",
    "    \n",
    "    plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotzi(kzdata_byday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
