{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import necessary modules\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import date2num, AutoDateFormatter, AutoDateLocator, WeekdayLocator, MonthLocator, DayLocator, DateLocator, DateFormatter\n",
    "from matplotlib.dates import MO, TU, WE, TH, FR, SA, SU\n",
    "from matplotlib.ticker import AutoMinorLocator, AutoLocator, FormatStrFormatter, ScalarFormatter\n",
    "import numpy as np\n",
    "import datetime, calendar\n",
    "from datetime import timedelta\n",
    "import matplotlib.patches as mpatches\n",
    "from itertools import tee\n",
    "\n",
    "sys.path.append(os.path.abspath('/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/entwuerfe/xls_testruns/'))\n",
    "from ce_funclib import determine_kernzeit as dtkz\n",
    "from ce_funclib import continuity_check\n",
    "\n",
    "#%matplotlib inline\n",
    "%matplotlib tk\n",
    "\n",
    "\n",
    "## Import data frome pickle generated from muß ein file mit agentenstats sein\n",
    "arcpth='/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/test_stats/archiv/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## GET A LIST OF MATCHING .xls FILES FROM THE GIVEN DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collectxlfiles(arcpath):\n",
    "    xlfilelist=list()\n",
    "\n",
    "    for xlfile in os.listdir(arcpath):\n",
    "        if xlfile.startswith('CE_al'):\n",
    "            xlfileabs=os.path.join(arcpath,xlfile)\n",
    "            xlfilelist.append(xlfileabs)\n",
    "    return sorted(xlfilelist)\n",
    "\n",
    "xlfilelist=collectxlfiles(arcpth)\n",
    "#xlfilelist\n",
    "#examplefile=xlfilelist[233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### TEST FOR DATA IN FILE, SORT OUT EMPTY FILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## good dataframes do per definition not contain any zero values\n",
    "## fill bad DFs with nan?\n",
    "\n",
    "def filetoframe(exfile):\n",
    "    exframe=pd.read_excel(exfile) # this is a regular pd.DataFrame\n",
    "    datecell=exframe.iloc[0,1]\n",
    "    sheet_datetime=pd.to_datetime(datecell,format='%d.%m %Y : %H')\n",
    "    sheet_date=sheet_datetime.date()\n",
    "    \n",
    "    integritycheck=exframe.iloc[2,1] # files with data have \"agenten\" here, files with no calls have a 'nan'\n",
    "\n",
    "    if integritycheck != 'Agenten':\n",
    "        # if it's empty, keep date for filling it later\n",
    "        print('Exception: ', end='')\n",
    "        except_status='ex'\n",
    "        \n",
    "        usefulcols={0:'tstamp',1:'agent',3:'an',4:'be',22:'vl',24:'ht_float',29:'tt_float'} # map cols to decent names\n",
    "        exframe=exframe.reindex(columns=sorted(usefulcols.keys()))\n",
    "        exframe.rename(columns=usefulcols,inplace=True)        \n",
    "        exframe=exframe[0:1] # strip text rows and the mangled sum row\n",
    "        print(sheet_datetime)\n",
    "        \n",
    "        exframe['tstamp']=sheet_datetime\n",
    "        exframe['date']=sheet_date\n",
    "        exframe['agent']='platzhalter'\n",
    "        exframe[['wd','ww','mm','yy']]=exframe['tstamp'].dt.strftime('%a,%W,%m,%Y').str.split(',',expand=True) # make ww,yy,mm,wd columns\n",
    "        exframe['bz']=exframe['tstamp'].apply(dtkz)\n",
    "        exframe['ort']=exframe['agent'].str[0] # split the identifier into useable columns\n",
    "        exframe['id']='foobar' # split the identifier into useable columns\n",
    "        \n",
    "        # integers should be of appropriate datatype, we received them as strings\n",
    "        # exframe[['vl','an','be','ww','mm','yy']]=exframe[['vl','an','be','ww','mm','yy']].astype(np.int64) #just for the beauty of it\n",
    "        exframe[['ww','mm','yy']]=exframe[['ww','mm','yy']].astype(np.int64) #just for the beauty of it\n",
    "        # exframe.fillna(0, inplace=True) \n",
    "        return exframe,except_status\n",
    "        \n",
    "    else:\n",
    "        except_status='reg'\n",
    "        \n",
    "        exframe.columns=range(0,30) # rename columns to a temporarily more readable format, fancy rename later\n",
    "        usefulcols={0:'tstamp',1:'agent',3:'an',4:'be',22:'vl',24:'ht_float',29:'tt_float'} # map cols to decent names\n",
    "        exframe=exframe[sorted(usefulcols.keys())] # skip cols and keep the ones we need\n",
    "        exframe.rename(columns=usefulcols,inplace=True) # rename cols\n",
    "        exframe=exframe[3:-1] # strip text rows and the mangled sum row\n",
    "        exframe['tstamp']=pd.to_datetime(exframe['tstamp'],format=' %d.%m.%Y %H:%M ')\n",
    "        exframe['date']=exframe['tstamp'].dt.date\n",
    "        exframe[['wd','ww','mm','yy']]=exframe['tstamp'].dt.strftime('%a,%W,%m,%Y').str.split(',',expand=True) # make ww,yy,mm,wd columns\n",
    "        exframe['bz']=exframe['tstamp'].apply(dtkz)\n",
    "        \n",
    "        exframe['ort']=exframe['agent'].str[0] # split the identifier into useable columns\n",
    "        exframe['id']=exframe['agent'].str[-6:] # split the identifier into useable columns\n",
    "        exframe['agent']=exframe['agent'].str[2:-7] # split the identifier into useable columns\n",
    "        \n",
    "        # integers should be of appropriate datatype, we received them as strings\n",
    "        exframe[['vl','an','be','ww','mm','yy']]=exframe[['vl','an','be','ww','mm','yy']].astype(np.int64) #just for the beauty of it\n",
    "\n",
    "        return exframe,except_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: 2017-04-17 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tstamp</th>\n",
       "      <th>agent</th>\n",
       "      <th>an</th>\n",
       "      <th>be</th>\n",
       "      <th>vl</th>\n",
       "      <th>ht_float</th>\n",
       "      <th>tt_float</th>\n",
       "      <th>date</th>\n",
       "      <th>wd</th>\n",
       "      <th>ww</th>\n",
       "      <th>mm</th>\n",
       "      <th>yy</th>\n",
       "      <th>bz</th>\n",
       "      <th>ort</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>platzhalter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>Mon</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>n</td>\n",
       "      <td>p</td>\n",
       "      <td>foobar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tstamp        agent  an  be  vl  ht_float  tt_float        date   wd  \\\n",
       "0 2017-04-17  platzhalter NaN NaN NaN       NaN       NaN  2017-04-17  Mon   \n",
       "\n",
       "   ww  mm    yy bz ort      id  \n",
       "0  16   4  2017  n   p  foobar  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_badframe,badstatus=filetoframe('/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/test_stats/archiv/CE_alle_Agenten_taeglich_2017-04-17.xls')\n",
    "example_goodframe,goodstatus=filetoframe('/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/test_stats/archiv/CE_alle_Agenten_taeglich_2017-05-17.xls')\n",
    "example_badframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tstamp</th>\n",
       "      <th>agent</th>\n",
       "      <th>an</th>\n",
       "      <th>be</th>\n",
       "      <th>vl</th>\n",
       "      <th>ht_float</th>\n",
       "      <th>tt_float</th>\n",
       "      <th>date</th>\n",
       "      <th>wd</th>\n",
       "      <th>ww</th>\n",
       "      <th>mm</th>\n",
       "      <th>yy</th>\n",
       "      <th>bz</th>\n",
       "      <th>ort</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-17 07:00:00</td>\n",
       "      <td>pletaan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>Wed</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>n</td>\n",
       "      <td>B</td>\n",
       "      <td>335334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-17 13:00:00</td>\n",
       "      <td>pletaan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4833</td>\n",
       "      <td>7.4833</td>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>Wed</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>k</td>\n",
       "      <td>B</td>\n",
       "      <td>335334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-05-17 15:00:00</td>\n",
       "      <td>beckeca</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>Wed</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>k</td>\n",
       "      <td>H</td>\n",
       "      <td>428869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tstamp    agent  an  be  vl ht_float tt_float        date   wd  \\\n",
       "3 2017-05-17 07:00:00  pletaan   1   1   0   0.8333     0.35  2017-05-17  Wed   \n",
       "4 2017-05-17 13:00:00  pletaan   1   1   0   8.4833   7.4833  2017-05-17  Wed   \n",
       "5 2017-05-17 15:00:00  beckeca   1   1   0   2.4333   2.3333  2017-05-17  Wed   \n",
       "\n",
       "   ww  mm    yy bz ort      id  \n",
       "3  20   5  2017  n   B  335334  \n",
       "4  20   5  2017  k   B  335334  \n",
       "5  20   5  2017  k   H  428869  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_goodframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: 2017-04-17 00:00:00\n",
      "Exception: 2017-05-14 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/test_stats/archiv/CE_alle_Agenten_taeglich_2017-04-17.xls',\n",
       " '/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/test_stats/archiv/CE_alle_Agenten_taeglich_2017-05-14.xls']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framelist=list()\n",
    "exceptionlist=list()\n",
    "for xfile in xlfilelist:\n",
    "    \n",
    "    #print('file:',xfile)\n",
    "    frame_from_file,except_status=filetoframe(xfile)\n",
    "    #print(frame_from_file.columns)\n",
    "    #print(frame_from_file['date'])\n",
    "    if except_status=='ex':\n",
    "        exceptionlist.append(xfile)\n",
    "    framelist.append(frame_from_file)\n",
    "\n",
    "exceptionlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### produce a unified frame with all data and sort it by timstamp and agentname\n",
    "bigframeii=pd.concat(framelist)\n",
    "\n",
    "bigframeii.sort_values(['tstamp','agent'],inplace=True)\n",
    "bigframeii.reset_index(drop=True,inplace=True) # there you go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bigframeii\n",
    "# die exklusivlogins müssen zusammengelegt werden\n",
    "unify_id={'gesinst':'995887','stanzju':'878457','papkeda':'891914'}\n",
    "bigframeii.loc[bigframeii['id'] == unify_id['gesinst'],'agent'] = 'gesinst'\n",
    "bigframeii.loc[bigframeii['id'] == unify_id['stanzju'],'agent'] = 'stanzju'\n",
    "bigframeii.loc[bigframeii['id'] == unify_id['papkeda'],'agent'] = 'papkeda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### some date locator play, can conveniently be checked against a single xls file\n",
    "#def check_single_day(day):\n",
    "#    dayvalues=bigframeii.loc[bigframeii['date'] == day]\n",
    "#    print('htsum',dayvalues['ht_float'].sum(), end=', ')\n",
    "#    print('bearbeitete sum',dayvalues['be'].sum())\n",
    "#check_single_day(datetime.date(2017,4,17)) # shows that days wihtout calls are in the frame, too\n",
    "#check_single_day(datetime.date(2017,4,18)) # shows that days wihtout calls are in the frame, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no dates are missing\n"
     ]
    }
   ],
   "source": [
    "#### get all dates and check whether they're contiguous\n",
    "datenserie_uniq=bigframeii['date'].unique().tolist()\n",
    "tage_bestand=len(datenserie_uniq)\n",
    "tage_start=datenserie_uniq[0]\n",
    "tage_ende=datenserie_uniq[-1:]\n",
    "\n",
    "missing_dates=continuity_check(datenserie_uniq)\n",
    "if not missing_dates:\n",
    "    print('no dates are missing')\n",
    "else:\n",
    "    print('the following dates are not within the frame:')\n",
    "    print(missing_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### PARSE AGENT DATA\n",
    "### What I want:\n",
    "### * get a list of all agents that have worked in the period \n",
    "### * get data for each agent\n",
    "### * get average of all agents as a reference\n",
    "### per agent:\n",
    "### ** get all calls that have lasted longer than x times the average of all agents\n",
    "### ** get a plot of all calls (by timestamp)\n",
    "### ** get a plot of all days (by date)\n",
    "### ** get their tendencies over the weeks (? vacation dates missing and so on)\n",
    "\n",
    "# bigframeii.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all agents available and create frames for kern and neben\n",
    "allagents_list=sorted(bigframeii['agent'].unique())\n",
    "allagents_list.extend(['Hagenow','Berlin','Alle'])\n",
    "standorte=bigframeii.ort.unique().tolist()\n",
    "\n",
    "bigk=bigframeii.loc[bigframeii['bz']=='k']\n",
    "bign=bigframeii.loc[bigframeii['bz']=='n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we can't figure out individual calls anyway, since raw data calls have been grouped by hours already  \n",
    "so we can go on and group by days to figure out averages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_and_add_average(agentname,frame,gruppierung):\n",
    "    # step one: filter by agent; if agent is a location-bound group, filter by location and change agent name to group name\n",
    "    if agentname == 'Hagenow':\n",
    "        nur_agent=frame.loc[frame['ort']=='H'].copy()\n",
    "        nur_agent['agent']='Hagenow'\n",
    "        nur_agent['id']='000001'\n",
    "    elif agentname == 'Berlin':\n",
    "        nur_agent=frame.loc[frame['ort']=='B'].copy()\n",
    "        nur_agent['agent']='Berlin'\n",
    "        nur_agent['id']='000002'\n",
    "    elif agentname == 'Alle':\n",
    "        #nur_agent=frame.loc[frame['ort'].isin(standorte)].copy()\n",
    "        nur_agent=frame.copy()\n",
    "        nur_agent['agent']='Alle'\n",
    "        nur_agent['id']='000000'    \n",
    "    else:\n",
    "        nur_agent=frame.loc[frame['agent']==agentname]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # step 2: split into kern and neben\n",
    "    k=nur_agent.loc[nur_agent['bz']=='k']\n",
    "    if k.empty:\n",
    "        print()\n",
    "        print(agentname,end=' ')\n",
    "        print('keine Kernzeit group_and_add_average')\n",
    "        print('###')\n",
    "        \n",
    "    n=nur_agent.loc[nur_agent['bz']=='n']\n",
    "    if n.empty:\n",
    "        print()\n",
    "        print(agentname,end=' ')\n",
    "        print('keine Nebenzeit group_and_add_average')\n",
    "        print('###')\n",
    "\n",
    "    # step 3: group by day (instead of hour, as it is now) and add average ht,tt\n",
    "    def group_and_average(agframe):\n",
    "        ### ttstamp is dropped and date will be the new index; all others summed or reduced\n",
    "        colfx_day={'agent':'first','an':'sum','be':'sum','vl':'sum','ht_float':'sum','tt_float':'sum','wd':'first','ww':'first', 'mm':'first','yy':'first','bz':'first','ort':'first','id':'first'}\n",
    "        ### ttstamp is dropped, date is dropped and ww will be the new index; all others summed or reduced\n",
    "        colfx_week={'agent':'first','an':'sum','be':'sum','vl':'sum','ht_float':'sum','tt_float':'sum','wd':'first','mm':'first','yy':'first','bz':'first','ort':'first','id':'first'}\n",
    "        \n",
    "        if gruppierung=='tag':\n",
    "            grpd=agframe.groupby('date').agg(colfx_day)\n",
    "        elif gruppierung=='woche':\n",
    "            grpd=agframe.groupby('ww').agg(colfx_week)\n",
    "        elif gruppierung=='nursplit':\n",
    "            grpd=agframe.copy()\n",
    "        \n",
    "        grpd['aht']=grpd['ht_float']/grpd['be']\n",
    "        grpd['att']=grpd['tt_float']/grpd['be']\n",
    "        grpd['acw']=grpd['aht']-grpd['att']\n",
    "\n",
    "        return grpd\n",
    "\n",
    "    # step 4 get stats grouped by day and with the average column\n",
    "    k_agent=group_and_average(k)\n",
    "    n_agent=group_and_average(n)\n",
    "\n",
    "    return k_agent,n_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**dictionary of frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting and grouping times (neben, kern) for\n",
      "\n",
      "haustst keine Nebenzeit group_and_add_average\n",
      "###\n",
      "\n",
      "haustst keine Nebenzeit group_and_add_average\n",
      "###\n",
      "\n",
      "jakobir keine Kernzeit group_and_add_average\n",
      "###\n",
      "\n",
      "jakobir keine Kernzeit group_and_add_average\n",
      "###\n",
      "\n",
      "platzhalter keine Kernzeit group_and_add_average\n",
      "###\n",
      "\n",
      "platzhalter keine Kernzeit group_and_add_average\n",
      "###\n",
      "\n",
      "reismat keine Nebenzeit group_and_add_average\n",
      "###\n",
      "\n",
      "reismat keine Nebenzeit group_and_add_average\n",
      "###\n",
      "\n",
      "steffci keine Nebenzeit group_and_add_average\n",
      "###\n",
      "\n",
      "steffci keine Nebenzeit group_and_add_average\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "### generate frames grouped by day and by week for every agent, put them in a dictionary\n",
    "zeiten={}\n",
    "print('collecting and grouping times (neben, kern) for')\n",
    "for namen in allagents_list:\n",
    "    kern_byday,neben_byday=group_and_add_average(namen,bigframeii,'tag')\n",
    "    kern_byweek,neben_byweek=group_and_add_average(namen,bigframeii,'woche')\n",
    "    \n",
    "    zeiten[namen]={'k_day':kern_byday,'k_week':kern_byweek,'n_day':neben_byday,'n_week':neben_byweek}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeiten['haustst']['n_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decminutes_to_mmss(decimal):\n",
    "    #print(decimal)\n",
    "    tdelta=timedelta(minutes=decimal)\n",
    "    sekunden=tdelta.seconds\n",
    "    minuten=(sekunden % 3600) // 60\n",
    "    restsekunden=str(sekunden %60).zfill(2)\n",
    "    mmssstring='{}:{}'.format(minuten, restsekunden)\n",
    "    return mmssstring\n",
    "\n",
    "def maptix2labels(ticks):\n",
    "    ylabelz=list()\n",
    "    for tic in ticks:\n",
    "        #print(tic)\n",
    "        tic=abs(tic)\n",
    "        sstr=decminutes_to_mmss(tic)\n",
    "        ylabelz.append(sstr)\n",
    "    return ylabelz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# colors\n",
    "bgkern='#FFF7F2'\n",
    "bgnebn='#F8FFF2'\n",
    "aht=\"#21a9ff\"\n",
    "att=\"#ceecff\"\n",
    "aac=\"#c4c4c4\"\n",
    "zielzeit=\"#FF006E\"\n",
    "bars=\"#A06A00\"\n",
    "aav='#000C00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotit(agent,ww_or_dd):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, sharey=False, figsize=(17,7))\n",
    "    \n",
    "    ### preliminary deduction from parameters\n",
    "    if ww_or_dd.lower() == 'woche':\n",
    "        kzeit=zeiten[agent]['k_week'].copy()\n",
    "        nzeit=zeiten[agent]['n_week'].copy()\n",
    "    elif ww_or_dd.lower() == 'tage':\n",
    "        kzeit=zeiten[agent]['k_day'].copy()\n",
    "        nzeit=zeiten[agent]['n_day'].copy()\n",
    "        \n",
    "    ### check empty frames\n",
    "    if (kzeit.empty and nzeit.empty):\n",
    "        print('ueberhaupt keine Calls')\n",
    "    elif kzeit.empty:\n",
    "        print('keine calls in der Kernzeit')\n",
    "        kzeit=kzeit.reindex(nzeit.index)#.fillna(0)\n",
    "    elif nzeit.empty:\n",
    "        print('keine calls in der Nebenzeit')\n",
    "        nzeit=nzeit.reindex(kzeit.index)#.fillna(0)\n",
    "\n",
    "\n",
    "    kmax=(kzeit['aht'].max())+0.5\n",
    "    nmax=(nzeit['aht'].max())+0.5\n",
    "    commonmax=max(kmax,nmax)\n",
    "    commonmin=-0.25\n",
    "    \n",
    "    ersterZeitpunkt=min(min(kzeit.index),min(nzeit.index))\n",
    "    letzterZeitpunkt=max(kzeit.index[-1],nzeit.index[-1])\n",
    "    StartStr=str(ersterZeitpunkt)\n",
    "    EndeStr=str(letzterZeitpunkt)\n",
    "    \n",
    "    calls_zeitraum_k=kzeit['be'].sum()\n",
    "    calls_zeitraum_n=nzeit['be'].sum()\n",
    "    \n",
    "\n",
    "    htmean_k=kzeit['aht'].replace(0,np.NaN).mean()\n",
    "    if np.isnan(htmean_k):\n",
    "        print('this is nan')\n",
    "        htmean_k=0\n",
    "    htmean_n=nzeit['aht'].replace(0,np.NaN).mean() # decent mean value without the zeroes jan-mar\n",
    "    if np.isnan(htmean_n):\n",
    "        print('this is nan')\n",
    "        htmean_n=0\n",
    "    av_all_k=zeiten['Alle']['k_week']['aht'].replace(0,np.NaN).mean()\n",
    "    av_all_n=zeiten['Alle']['n_week']['aht'].replace(0,np.NaN).mean()\n",
    "\n",
    "    ### plots\n",
    "\n",
    "    ax3 = ax1.twinx()\n",
    "    ax3.tick_params('y', labelsize=6, labelcolor=bars)\n",
    "\n",
    "    ax4 = ax2.twinx()\n",
    "    ax4.tick_params('y', labelsize=6, labelcolor=bars)\n",
    "\n",
    "    kcalls=ax3.bar(kzeit.index, kzeit['be'], width=0.7, alpha=0.1, color=bars, label='calls')\n",
    "    ncalls=ax4.bar(nzeit.index, nzeit['be'], width=0.7, alpha=0.1, color=bars, label='calls')\n",
    "\n",
    "    kaht,=ax1.plot(kzeit.index,kzeit['aht'],color=aht,label=\"aht\")\n",
    "    katt,=ax1.plot(kzeit.index,kzeit['att'],color=att,label=\"att\")\n",
    "    kacw,=ax1.plot(kzeit.index,kzeit['acw'],color=aac,label=\"acw\")\n",
    "    naht,=ax2.plot(nzeit.index,nzeit['aht'],color=aht,label=\"aht\")\n",
    "    natt,=ax2.plot(nzeit.index,nzeit['att'],color=att,label=\"att\")\n",
    "    nacw,=ax2.plot(nzeit.index,nzeit['acw'],color=aac,label=\"acw\")\n",
    "\n",
    "    kziel=ax1.axhline(y=3.5,color=zielzeit,ls=':',alpha=0.75, label='3:30 min')\n",
    "    kreal=ax1.axhline(y=htmean_k,color=aht,ls='--',alpha=0.9, label=str(decminutes_to_mmss(htmean_k)))\n",
    "    kalle=ax1.axhline(y=av_all_k,color=aav,ls='-.',alpha=0.2, label=str(decminutes_to_mmss(av_all_k)))\n",
    "    nziel=ax2.axhline(y=1.5,color=zielzeit,ls=':',alpha=0.75, label='1:30 min')\n",
    "    nreal=ax2.axhline(y=htmean_n,color=aht,ls='--',alpha=0.9, label=str(decminutes_to_mmss(htmean_n)))\n",
    "    nalle=ax2.axhline(y=av_all_n,color=aav,ls='-.',alpha=0.2, label=str(decminutes_to_mmss(av_all_n)))\n",
    "\n",
    "    ### ax1 labels\n",
    "    ax1.set_ylim(commonmin,commonmax)\n",
    "\n",
    "    minloc=AutoMinorLocator(4)\n",
    "    ax1.yaxis.set_minor_locator(minloc)\n",
    "    ax1.yaxis.set_minor_formatter(ScalarFormatter()) # is the same as major formatter\n",
    "\n",
    "    left_tix_mj=ax1.get_yticks()\n",
    "    left_tix_mn=ax1.get_yticks(minor=True)\n",
    "    left_lbl_mj=maptix2labels(left_tix_mj)\n",
    "    left_lbl_mn=maptix2labels(left_tix_mn)\n",
    "\n",
    "    ax1.yaxis.set_ticklabels(left_lbl_mj)\n",
    "    ax1.yaxis.set_ticklabels(left_lbl_mn,minor=True,size=6)\n",
    "\n",
    "\n",
    "    ### ax2 labels\n",
    "    ax2.set_ylim(ax1.get_ylim())\n",
    "\n",
    "    ax2.yaxis.set_minor_locator(minloc)\n",
    "    ax2.yaxis.set_minor_formatter(ScalarFormatter()) # is the same as major formatter\n",
    "\n",
    "    left_tix_mj=ax2.get_yticks()\n",
    "    left_tix_mn=ax2.get_yticks(minor=True)\n",
    "    left_lbl_mj=maptix2labels(left_tix_mj)\n",
    "    left_lbl_mn=maptix2labels(left_tix_mn)\n",
    "\n",
    "    ax2.yaxis.set_ticklabels(left_lbl_mj)\n",
    "    ax2.yaxis.set_ticklabels(left_lbl_mn,minor=True,size=6)\n",
    "\n",
    "    ### color adjustments, titles, legend\n",
    "    ax1.set_facecolor(bgkern)\n",
    "    ax2.set_facecolor(bgnebn)\n",
    "\n",
    "    desc_k,desc_n=str(int(calls_zeitraum_k)),str(int(calls_zeitraum_n))\n",
    "    ax1.set_title('Kernzeit'+' Calls gesamt: '+desc_k, size=9)\n",
    "    ax2.set_title('Nebenzeit'+' Calls gesamt: '+desc_n, size=9)\n",
    "\n",
    "    ax1.set_xlabel(ww_or_dd, size=7)\n",
    "    ax2.set_xlabel(ww_or_dd, size=7)\n",
    "    ax1.tick_params('x', labelsize=8)\n",
    "    ax2.tick_params('x', labelsize=8)\n",
    "\n",
    "    ax1.set_ylabel('Minuten', rotation=90)\n",
    "    ax4.set_ylabel('Calls',rotation=90,color=bars)\n",
    "\n",
    "    f.suptitle('Bearbeitungszeiten '+agent+' nach '+ww_or_dd+' ab März 2017 bis '+ww_or_dd+' '+EndeStr)\n",
    "\n",
    "    f.legend((kaht,katt,kacw,kziel,kreal,kalle,kcalls),('handling','talk','afterwork','zielzeit','Øzeit agent','Øzeit alle','calls'),fontsize=7,ncol=2,loc='upper right',borderaxespad=2)\n",
    "\n",
    "    \n",
    "    ### Abspeichern\n",
    "    heute=datetime.date.today().strftime('%Y_%m_%d')\n",
    "    bild_filename=str(heute+'_'+agent+'_'+ww_or_dd+'_'+StartStr+'-'+EndeStr)\n",
    "    savepath='/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/ce_teamleitung/plots/agenten_und_standorte/'\n",
    "    speichernin=os.path.join(savepath,bild_filename)\n",
    "    print(speichernin)\n",
    "    #f.savefig(speichernin,ext='png')\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in allagents_list[10:11]:\n",
    "    print(person)\n",
    "    plotit(person,'Woche')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### isin function is pretty neat thing for filtering\n",
    "#### obviously, ww is another datatype than mm, normalization required!\n",
    "zeiten['gesinst']['n_day'].loc[zeiten['gesinst']['n_day']['ww'].isin([32,33,34,35,36,37,38,39,40,41])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
