{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import necessary modules\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import date2num, AutoDateFormatter, AutoDateLocator, WeekdayLocator, MonthLocator, DayLocator, DateLocator, DateFormatter\n",
    "from matplotlib.dates import MO, TU, WE, TH, FR, SA, SU\n",
    "from matplotlib.ticker import AutoMinorLocator, AutoLocator, FormatStrFormatter, ScalarFormatter\n",
    "import numpy as np\n",
    "import datetime, calendar\n",
    "from datetime import timedelta\n",
    "import matplotlib.patches as mpatches\n",
    "from itertools import tee\n",
    "from traitlets import traitlets\n",
    "\n",
    "sys.path.append(os.path.abspath('/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/entwuerfe/xls_testruns/lib/'))\n",
    "from ce_funclib import determine_kernzeit as dtkz\n",
    "from ce_funclib import continuity_check\n",
    "\n",
    "\n",
    "from ipywidgets import widgets, interact, interactive, fixed, interact_manual, Layout\n",
    "from IPython.display import display\n",
    "#%matplotlib inline\n",
    "%matplotlib tk\n",
    "\n",
    "\n",
    "## Import data frome pickle generated from muß ein file mit agentenstats sein\n",
    "arcpth='/home/keuch/gits/keuch/code_box/pyt/spreadsheetparsing/test_stats/archiv/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## GET A LIST OF MATCHING .xls FILES FROM THE GIVEN DIRECTORY\n",
    "\n",
    "def collectxlfiles(arcpath):\n",
    "    xlfilelist=list()\n",
    "\n",
    "    for xlfile in os.listdir(arcpath):\n",
    "        if xlfile.startswith('CE_al'):\n",
    "            xlfileabs=os.path.join(arcpath,xlfile)\n",
    "            xlfilelist.append(xlfileabs)\n",
    "    return sorted(xlfilelist)\n",
    "\n",
    "xlfilelist=collectxlfiles(arcpth)\n",
    "#xlfilelist\n",
    "#examplefile=xlfilelist[233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### TEST FOR DATA IN FILE, SORT OUT EMPTY FILES\n",
    "\n",
    "## good dataframes do per definition not contain any zero values\n",
    "## fill bad DFs with nan?\n",
    "\n",
    "def filetoframe(exfile):\n",
    "    exframe=pd.read_excel(exfile) # this is a regular pd.DataFrame\n",
    "    datecell=exframe.iloc[0,1]\n",
    "    sheet_datetime=pd.to_datetime(datecell,format='%d.%m %Y : %H')\n",
    "    sheet_date=sheet_datetime.date()\n",
    "    \n",
    "    integritycheck=exframe.iloc[2,1] # files with data have \"agenten\" here, files with no calls have a 'nan'\n",
    "\n",
    "    if integritycheck != 'Agenten':\n",
    "        # if it's empty, keep date for filling it later\n",
    "        print('Exception: ', end='')\n",
    "        except_status='ex'\n",
    "        \n",
    "        usefulcols={0:'tstamp',1:'agent',3:'an',4:'be',22:'vl',24:'ht_float',29:'tt_float'} # map cols to decent names\n",
    "        exframe=exframe.reindex(columns=sorted(usefulcols.keys()))\n",
    "        exframe.rename(columns=usefulcols,inplace=True)        \n",
    "        exframe=exframe[0:1] # strip text rows and the mangled sum row\n",
    "        print(sheet_datetime)\n",
    "        \n",
    "        exframe['tstamp']=sheet_datetime\n",
    "        exframe['date']=sheet_date\n",
    "        exframe['agent']='nocalls_datum'\n",
    "        exframe[['wd','ww','mm','yy']]=exframe['tstamp'].dt.strftime('%a,%W,%m,%Y').str.split(',',expand=True) # make ww,yy,mm,wd columns\n",
    "        exframe['bz']=exframe['tstamp'].apply(dtkz)\n",
    "        exframe['ort']=exframe['agent'].str[0] # split the identifier into useable columns\n",
    "        exframe['id']='foobar' # split the identifier into useable columns\n",
    "        \n",
    "        # integers should be of appropriate datatype, we received them as strings\n",
    "        # exframe[['vl','an','be','ww','mm','yy']]=exframe[['vl','an','be','ww','mm','yy']].astype(np.int64) #just for the beauty of it\n",
    "        exframe.fillna(0, inplace=True) \n",
    "        exframe[['ww','mm','yy']]=exframe[['ww','mm','yy']].astype(np.int64) #just for the beauty of it\n",
    "        #exframe.fillna(0, inplace=True) \n",
    "        return exframe,except_status\n",
    "        \n",
    "    else:\n",
    "        except_status='reg'\n",
    "        \n",
    "        exframe.columns=range(0,30) # rename columns to a temporarily more readable format, fancy rename later\n",
    "        usefulcols={0:'tstamp',1:'agent',3:'an',4:'be',22:'vl',24:'ht_float',29:'tt_float'} # map cols to decent names\n",
    "        exframe=exframe[sorted(usefulcols.keys())] # skip cols and keep the ones we need\n",
    "        exframe.rename(columns=usefulcols,inplace=True) # rename cols\n",
    "        exframe=exframe[3:-1] # strip text rows and the mangled sum row\n",
    "        exframe['tstamp']=pd.to_datetime(exframe['tstamp'],format=' %d.%m.%Y %H:%M ')\n",
    "        exframe['date']=exframe['tstamp'].dt.date\n",
    "        exframe[['wd','ww','mm','yy']]=exframe['tstamp'].dt.strftime('%a,%W,%m,%Y').str.split(',',expand=True) # make ww,yy,mm,wd columns\n",
    "        exframe['bz']=exframe['tstamp'].apply(dtkz)\n",
    "        \n",
    "        exframe['ort']=exframe['agent'].str[0] # split the identifier into useable columns\n",
    "        exframe['id']=exframe['agent'].str[-6:] # split the identifier into useable columns\n",
    "        exframe['agent']=exframe['agent'].str[2:-7] # split the identifier into useable columns\n",
    "        \n",
    "        # integers should be of appropriate datatype, we received them as strings\n",
    "        exframe[['vl','an','be','ww','mm','yy']]=exframe[['vl','an','be','ww','mm','yy']].astype(np.int64) #just for the beauty of it\n",
    "\n",
    "        return exframe,except_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: 2017-04-17 00:00:00\n",
      "Exception: 2017-05-14 00:00:00\n",
      "Exception: 2017-11-19 00:00:00\n",
      "Exception: 2017-12-03 00:00:00\n",
      "Exception: 2017-12-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "framelist=list()\n",
    "exceptionlist=list()\n",
    "for xfile in xlfilelist:\n",
    "    frame_from_file,except_status=filetoframe(xfile)\n",
    "    if except_status=='ex':\n",
    "        exceptionlist.append(xfile)\n",
    "    framelist.append(frame_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### produce a unified frame with all data and sort it by timstamp and agentname\n",
    "bigframeii=pd.concat(framelist)\n",
    "bigframeii.sort_values(['tstamp','agent'],inplace=True)\n",
    "bigframeii.reset_index(drop=True,inplace=True) # there you go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# die exklusivlogins müssen zusammengelegt werden\n",
    "unify_id={'gesinst':'995887','stanzju':'878457','papkeda':'891914'}\n",
    "bigframeii.loc[bigframeii['id'] == unify_id['gesinst'],'agent'] = 'gesinst'\n",
    "bigframeii.loc[bigframeii['id'] == unify_id['stanzju'],'agent'] = 'stanzju'\n",
    "bigframeii.loc[bigframeii['id'] == unify_id['papkeda'],'agent'] = 'papkeda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no dates are missing\n"
     ]
    }
   ],
   "source": [
    "#### check, ob alle Daten(Tage) lückenlos sind\n",
    "datenserie_uniq=bigframeii['date'].unique().tolist()\n",
    "tage_bestand=len(datenserie_uniq)\n",
    "tage_start=datenserie_uniq[0]\n",
    "tage_ende=datenserie_uniq[-1:]\n",
    "\n",
    "missing_dates=continuity_check(datenserie_uniq)\n",
    "if not missing_dates:\n",
    "    print('no dates are missing')\n",
    "else:\n",
    "    print('the following dates are not within the frame:')\n",
    "    print(missing_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all agents available and create frames for kern and neben\n",
    "allagents_list=sorted(bigframeii['agent'].unique())\n",
    "allagents_list.extend(['Hagenow','Berlin','Alle'])\n",
    "standorte=bigframeii.ort.unique().tolist()\n",
    "\n",
    "bigk=bigframeii.loc[bigframeii['bz']=='k']\n",
    "bign=bigframeii.loc[bigframeii['bz']=='n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we can't figure out individual calls anyway, since raw data calls have been grouped by hours already  \n",
    "so we can go on and group by days to figure out averages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tstamp</th>\n",
       "      <th>agent</th>\n",
       "      <th>an</th>\n",
       "      <th>be</th>\n",
       "      <th>vl</th>\n",
       "      <th>ht_float</th>\n",
       "      <th>tt_float</th>\n",
       "      <th>date</th>\n",
       "      <th>wd</th>\n",
       "      <th>ww</th>\n",
       "      <th>mm</th>\n",
       "      <th>yy</th>\n",
       "      <th>bz</th>\n",
       "      <th>ort</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-04 08:00:00</td>\n",
       "      <td>beckfra</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3667</td>\n",
       "      <td>2.1333</td>\n",
       "      <td>2017-03-04</td>\n",
       "      <td>Sat</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>n</td>\n",
       "      <td>H</td>\n",
       "      <td>216694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-04 08:00:00</td>\n",
       "      <td>tetzlva</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6833</td>\n",
       "      <td>2.6167</td>\n",
       "      <td>2017-03-04</td>\n",
       "      <td>Sat</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>n</td>\n",
       "      <td>B</td>\n",
       "      <td>613887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tstamp    agent   an   be   vl ht_float tt_float        date  \\\n",
       "0 2017-03-04 08:00:00  beckfra  1.0  1.0  0.0   2.3667   2.1333  2017-03-04   \n",
       "1 2017-03-04 08:00:00  tetzlva  1.0  1.0  0.0   2.6833   2.6167  2017-03-04   \n",
       "\n",
       "    wd  ww  mm    yy bz ort      id  \n",
       "0  Sat   9   3  2017  n   H  216694  \n",
       "1  Sat   9   3  2017  n   B  613887  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigframeii.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_and_add_average(agentname,frame,gruppierung):\n",
    "    # step one: filter by agent; if agent is a location-bound group, filter by location and change agent name to group name\n",
    "    if agentname == 'Hagenow':\n",
    "        nur_agent=frame.loc[frame['ort']=='H'].copy()\n",
    "        nur_agent['agent']='Hagenow'\n",
    "        nur_agent['id']='000001'\n",
    "    elif agentname == 'Berlin':\n",
    "        nur_agent=frame.loc[frame['ort']=='B'].copy()\n",
    "        nur_agent['agent']='Berlin'\n",
    "        nur_agent['id']='000002'\n",
    "    elif agentname == 'Alle':\n",
    "        #nur_agent=frame.loc[frame['ort'].isin(standorte)].copy()\n",
    "        nur_agent=frame.copy()\n",
    "        nur_agent['agent']='Alle'\n",
    "        nur_agent['id']='000000'    \n",
    "    else:\n",
    "        nur_agent=frame.loc[frame['agent']==agentname]\n",
    "    \n",
    "\n",
    "    # step 2: split into kern and neben\n",
    "    k=nur_agent.loc[nur_agent['bz']=='k']\n",
    "    if k.empty:\n",
    "        print('.',end=' ')\n",
    "        #print(agentname,end=' ')\n",
    "        #print('keine Kernzeit group_and_add_average')\n",
    "        #print('###')\n",
    "        \n",
    "    n=nur_agent.loc[nur_agent['bz']=='n']\n",
    "    if n.empty:\n",
    "        print('.',end=' ')\n",
    "        #print(agentname,end=' ')\n",
    "        #print('keine Nebenzeit group_and_add_average')\n",
    "        #print('###')\n",
    "\n",
    "    # step 3: group by day (instead of hour, as it is now) and add average ht,tt\n",
    "    def group_and_average(agframe):\n",
    "        ### ttstamp is dropped and date will be the new index; all others summed or reduced\n",
    "        colfx_day={'agent':'first','an':'sum','be':'sum','vl':'sum','ht_float':'sum','tt_float':'sum','wd':'first','ww':'first', 'mm':'first','yy':'first','bz':'first','ort':'first','id':'first'}\n",
    "        ### ttstamp is dropped, date is dropped and ww will be the new index; all others summed or reduced\n",
    "        colfx_week={'agent':'first','an':'sum','be':'sum','vl':'sum','ht_float':'sum','tt_float':'sum','wd':'first','mm':'first','yy':'first','bz':'first','ort':'first','id':'first'}\n",
    "        \n",
    "        if gruppierung=='tag':\n",
    "            grpd=agframe.groupby('date').agg(colfx_day)\n",
    "        elif gruppierung=='woche':\n",
    "            grpd=agframe.groupby('ww').agg(colfx_week)\n",
    "        elif gruppierung=='nursplit':\n",
    "            grpd=agframe.copy()\n",
    "        \n",
    "        grpd['aht']=grpd['ht_float']/grpd['be']\n",
    "        grpd['att']=grpd['tt_float']/grpd['be']\n",
    "        grpd['acw']=grpd['aht']-grpd['att']\n",
    "\n",
    "        return grpd\n",
    "\n",
    "    # step 4 get stats grouped by day and with the average column\n",
    "    k_agent=group_and_average(k)\n",
    "    n_agent=group_and_average(n)\n",
    "\n",
    "    return k_agent,n_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**dictionary of frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate frames grouped by day and by week for every agent, put them in a dictionary\n",
    "\n",
    "#zeiten={}\n",
    "#print('collecting and grouping times (neben, kern) for')\n",
    "#for namen in allagents_list:\n",
    "#    kern_byday,neben_byday=group_and_add_average(namen,bigframeii,'tag')\n",
    "#    kern_byweek,neben_byweek=group_and_add_average(namen,bigframeii,'woche')\n",
    "#    zeiten[namen]={'k_day':kern_byday,'k_week':kern_byweek,'n_day':neben_byday,'n_week':neben_byweek}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### isin function is pretty neat thing for filtering\n",
    "#### obviously, ww is another datatype than mm, normalization required!\n",
    "\n",
    "#zeiten['gesinst']['n_day'].loc[zeiten['gesinst']['n_day']['ww'].isin([32,33,34,35,36,37,38,39,40,41])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sortlist(frame,sortby):\n",
    "    print(sortby.lower())\n",
    "    overall_funx1={'be':'sum','ht_float':'sum'}\n",
    "    gesframe=frame.groupby('agent').agg(overall_funx1).copy()\n",
    "    gesframe['aht']=(gesframe['ht_float']/gesframe['be'])\n",
    "\n",
    "    overall_funx2={'be':'sum','ht_float':'sum'}\n",
    "    ortsframe=frame.loc[bigframeii['ort'].isin(['H','B'])].groupby('ort').agg(overall_funx2).copy()\n",
    "    ortsframe['aht']=(ortsframe['ht_float']/ortsframe['be'])\n",
    "\n",
    "    newf=ortsframe.rename(index={'B':'berlin','H':'hagenow'})\n",
    "    newf.index.names=['agent']\n",
    "    newfall=pd.concat([gesframe,newf]).fillna(0)\n",
    "    if sortby.lower() == 'calls':\n",
    "        newfall.sort_values('be',ascending=False,inplace=True)\n",
    "    elif sortby.lower() == 'aht':\n",
    "        newfall.sort_values('aht',ascending=False,inplace=True)\n",
    "    \n",
    "    #print(newfall)\n",
    "    \n",
    "    return newfall.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daten kommen von bigframeii\n",
      "calls\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c121f4a9fcc4af58bbb0b006dff2978"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# hier erstmal die Daten\n",
    "print('daten kommen von bigframeii')\n",
    "dats=sorted(bigframeii.date.unique())\n",
    "\n",
    "# Button einrichten, der einen Wiedergabewert hat\n",
    "class ReturnValueButton(widgets.Button):\n",
    "    \"\"\"A button that can holds a value as a attribute.\"\"\"\n",
    "\n",
    "    def __init__(self, value=None, *args, **kwargs):\n",
    "        super(ReturnValueButton, self).__init__(*args, **kwargs)\n",
    "        # Create the value attribute.\n",
    "        self.add_traits(value=traitlets.Any(value))\n",
    "\n",
    "\n",
    "# aufsetzen der Widgets, die in die Boxen kommen: \n",
    "agtsortmethod=widgets.RadioButtons(options=['Calls', 'avAHT'],value='Calls',description='Agenten sortiert nach:',disabled=False)\n",
    "agent_chooser=widgets.SelectMultiple(options=get_sortlist(bigframeii,agtsortmethod.value),layout=Layout(display=\"flex\", flex_flow='column'),description='Agents',disabled=False)\n",
    "ww_dd_chooser=widgets.RadioButtons(options=['Wochen', 'Einzeltage'],value='Wochen',description='Gruppierung:',disabled=False)\n",
    "whichweeks=widgets.IntRangeSlider(step=1,disabled=False,min=1,max=52,value=[1,52],description='Wochen')\n",
    "fromdt=widgets.SelectionSlider(options=dats,description='Von:')\n",
    "tilldt=widgets.SelectionSlider(options=dats, min=fromdt.value,max=dats[-1],description='Bis:')\n",
    "gobutton = ReturnValueButton(description=\"Click me\",disabled=False,button_style='',tooltip='Click me',icon='check',value=1)\n",
    "\n",
    "# layout der widget-boxen\n",
    "overbox=widgets.HBox(description='outer box',title='outer box', name='outer box', layout=Layout(border='2px solid black'))             # Das ist der Hauptcontainer, in den die weiteren Boxen kommen\n",
    "leftbox_agents=widgets.VBox(layout=Layout(border='2px solid blue'))      # linke Box innerhalb\n",
    "rightbox_timeranges=widgets.VBox(layout=Layout(border='2px solid purple')) # rechte Box innerhalb\n",
    "overbox.children=[leftbox_agents,rightbox_timeranges]               # so werden die Boxen im Container platziert\n",
    "leftbox_agents.children=[agtsortmethod,agent_chooser]               # widgets für die linke Box\n",
    "rightbox_timeranges.children=[ww_dd_chooser,whichweeks,gobutton]    # widgets für die rechte Box\n",
    "\n",
    "# 'observe'-Funktionen für die widgets:\n",
    "def shift_tilldt(args):\n",
    "    farom=dats.index(args['new'])\n",
    "    tilldt.options=dats[farom:]\n",
    "def switchflick(args):\n",
    "    wd=args['new']\n",
    "    #print(wd)\n",
    "    #print(rightbox_timeranges)\n",
    "    if wd=='Einzeltage':\n",
    "        rightbox_timeranges.children=[ww_dd_chooser,fromdt,tilldt,gobutton]\n",
    "    elif wd=='Wochen':\n",
    "        rightbox_timeranges.children=[ww_dd_chooser,whichweeks,gobutton]\n",
    "def agtsort(args):\n",
    "    sor=(args['new'])\n",
    "    #print(sor)\n",
    "    if sor.lower() == 'calls':\n",
    "        agent_chooser.options=get_sortlist(bigframeii,'calls')\n",
    "    elif sor.lower() == 'avaht':\n",
    "        agent_chooser.options=get_sortlist(bigframeii,'aht')\n",
    "def passvalues(args):\n",
    "    agenten=list(agent_chooser.value)\n",
    "    agenten.append('Alle')\n",
    "    print(type(agenten))\n",
    "    wwdd=ww_dd_chooser.value\n",
    "    zeitrahmen=tuple()\n",
    "    if wwdd.lower()=='wochen':\n",
    "        zeitrahmen=('ww',range(whichweeks.value[0],whichweeks.value[1]+1)) #soll als range ausgegeben werden, daher +1 auf den letzten Wert\n",
    "    elif wwdd.lower()=='einzeltage':\n",
    "        zeitrahmen=('date',pd.date_range(fromdt.value,tilldt.value))\n",
    "    args.value=tuple([agenten,zeitrahmen])\n",
    "\n",
    "\n",
    "# Zuweisung/Bindung der 'observe'-Funktionen an die widgets\n",
    "agtsortmethod.observe(agtsort,'value') \n",
    "# Erklärung: das widget 'agtsortmethod' hat als potentielle Values die beiden Werte,\n",
    "# die oben beim Start des Widgets als \"Options\" hinterlegt wurden (\"Calls\" und \"avAHT\")\n",
    "# wird das widget betätigt, wird sie funktion \"agtsort\" mit dem gerade gewählten Wert als Parameter aufgerufen\n",
    "# die Funktion setzt in einem anderen widget (agent_chooser) die zur Auswahl stehenden Werte direkt\n",
    "ww_dd_chooser.observe(switchflick,'value')\n",
    "fromdt.observe(shift_tilldt,'value')\n",
    "\n",
    "display(overbox)\n",
    "\n",
    "gobutton.on_click(passvalues)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterparams=gobutton.value\n",
    "\n",
    "namefilter=filterparams[0]\n",
    "timecol=filterparams[1][0]\n",
    "if timecol=='ww':\n",
    "    timerng=filterparams[1][1]\n",
    "elif timecol=='date':\n",
    "    timerng=filterparams[1][1].date\n",
    "\n",
    "#print(namefilter,timecol,timerng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hier der dataframe, der nur die gewünschten Agenten + Zeitraeume beinhaltet\n",
    "sframe=bigframeii.loc[(bigframeii['agent'].isin(namefilter)) & (bigframeii[timecol].isin(timerng))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting and grouping filtered times (neben, kern) for\n",
      "gesinst\n",
      "tonnroy\n",
      "hennisi\n",
      "laeweul\n",
      "Alle\n"
     ]
    }
   ],
   "source": [
    "# die plotfunktion arbeitet mit Dictionary, also aus dem Frame noch ein dict erzeugen, das nach Kern- und Nebenzeit trennt\n",
    "\n",
    "zeiten2={}\n",
    "print('collecting and grouping filtered times (neben, kern) for')\n",
    "for namen in namefilter:\n",
    "    print(namen)\n",
    "    kern_byday,neben_byday=group_and_add_average(namen,sframe,'tag')\n",
    "    kern_byweek,neben_byweek=group_and_add_average(namen,sframe,'woche')\n",
    "    zeiten2[namen]={'k_day':kern_byday,'k_week':kern_byweek,'n_day':neben_byday,'n_week':neben_byweek}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gesinst\n",
      "tonnroy\n",
      "hennisi\n",
      "laeweul\n"
     ]
    }
   ],
   "source": [
    "### paramter für plotit: \"woche\" und \"tage\"\n",
    "from ce_funclib import decminutes_to_mmss, maptix2labels, plotit\n",
    "for i in namefilter[:-1]:\n",
    "    print(i)\n",
    "    plotit(zeiten2,i,'tage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
